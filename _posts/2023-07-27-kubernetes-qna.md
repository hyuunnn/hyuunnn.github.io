---
layout: post
title: "쿠버네티스 질문 정리"
description: ""
date: 2023-07-27
tags: []
---

<a href="https://www.yes24.com/Product/Goods/102099414">컨테이너 인프라 환경 구축을 위한 쿠버네티스/도커</a> 책 정독을 강력 추천한다. 개인적으로 헷갈렸던 부분들이 질문과 답변 형식으로 정리되어 있었다.

<a href="https://www.yes24.com/Product/Goods/92426926">핵심만 콕! 쿠버네티스</a> 책은 마스터 노드 1개, 워커 노드 1개로 실습하는데, 위 책은 마스터 노드 1개, 워커 노드 3개로 실습한다. 

특히 첫 번째 책을 읽으면서 파드가 여러 개의 워커 노드에 적절하게 배치된다는 것을 눈으로 확인할 수 있었다. 

사실 워커 노드를 하나만 사용하면 쿠버네티스를 사용하는 의미가 없다. (워커 노드를 여러개 만들어서 분산시키는게 핵심이기 때문)

* 파드가 반영속적, 불안정하다(ephemeral)는 의미가 무엇인가? 
    * ```
      쿠버네티스의 설계 사상은 카오스 엔지니어링을 따르고 있으며, 컨테이너를 포함한 리소스는 늘 장애가 발생하거나 다운될 수 있다는 전제를 가정하고 있다.
      평소에 동일한 서비스를 제공하는 컨테이너를 준비하였다가 가용한 컨테이너로 서비스를 즉시 라우팅시키는 방법으로 서비스의 연속성을 제공한다.
      또한 최소 파드를 설정해놓으면 파드가 다운되더라도 서버 자원의 용량이 허용하는 범위 내에서 자동으로 최솟값의 파드를 항상 기동시킨다.
      즉 파드의 장애 발생 시 운영자가 이를 복구하기 위해서 신경 쓸 필요가 없다.

      실제로 사용자들의 경험담을 들어보아도 간혹 대시보드에 들어와보면 컨테이너가 수시로 재기동된 이력은 있는데,
      서비스는 다운타임이 발생한 적이 없다고 언급하는 것을 자주 접하며, 정확한 통계는 없지만 서비스 복구율도 전통적인 HA 솔루션보다 의외로 높다는 의견이 지배적이다.
      디지털 플랫폼 전략 수립을 위한 쿠버네티스 실전 활용서 - p103
      ```
    * 파드를 생성하기 전에 바라는 상태와 현재 상태를 확인한 후 다르다면 생성하는 구조이다. (선감시 후생성)
        * 파드가 죽지 않고 계속 살아있어야 함을 보장하지 않는다.
        * 파드가 죽었을 때 계속 살리는 것을 보장한다.
        * 파드를 강제로 삭제하더라도 컨트롤러에 정의한 상태를 유지하기 위해 파드를 다시 생성한다.
        * ```
          에어컨을 사용할 때 현재 상태(현재 온도)가 존재하고, 사용자가 바라는 상태(희망 온도)가 있습니다.
          에어컨 시스템이 현재 상태를 바라는 상태와 동일해지도록 제어하듯이 쿠버네티스도 자동으로 현재 상태를 바라는 상태로 변경합니다.
          바라는 상태를 가지는 것의 장점으로는 쿠버네티스에 장애가 발생하여 애플리케이션이 죽더라도 바라는 상태를 알기 때문에 손쉽게 원래의 바라는 상태로 배포 상태를 되살릴 수 있습니다. (자가 치유)
          핵심만 콕! 쿠버네티스 - p41
          ```
    * HPA(Horizontal Pod Autoscaler)
        * 설정한 사용률보다 올라가면 파드를 늘리고, 내려가면 파드가 줄어든다. 즉 파드가 규모에 따라서 삭제되거나 추가된다.
        * ```
          사용자가 갑자기 늘어난다면 어떻게 될까요?
          파드는 더 이상 감당할 수 없어서 서비스 불가라는 결과를 초래할 수도 있습니다.
          쿠버네티스는 이런 경우를 대비해 부하량에 따라 디플로이먼트의 파드 수를 유동적으로 관리하는 기능을 제공합니다.
          이를 HPA(Horizontal Pod Autoscaler)라고 합니다.
          컨테이너 인프라 환경 구축을 위한 쿠버네티스/도커 - p170
          ```
        * ```
          VPA(Vertical Pod Autoscaler)의 경우, 스케일 업을 수행하기 위해 파드를 제거하고 다시 배포하는 과정이 수행되면서 큰 오버헤드가 발생하기 때문에 일반적으로는 HPA가 많이 사용된다.
          오토스케일링 알고리즘 비교를 위한 요청 수 기반 쿠버네티스 Horizontal Pod Autoscaler 모델링 - 장용현 외 4명
          ```
            * VPA는 파드의 리소스가 부족한 경우, 파드를 스케일 업한다. (<a href="https://kimjingo.tistory.com/166">설명</a>)
        * ```
          이러한 자동 확장의 경우에도 파드가 기동될 노드들의 집합체 내 CPU나 Memory의 여유 자원이 존재해야 가능하며, 부족할 경우 자동 확장이 멈추기도 한다. 이럴 경우 퍼블릭 클라우드와 연계하여 파드를 확장한 후 글로벌 로드밸런싱을 수행하는 구성 전략까지 쉽게 구축할 수 있다.
          디지털 플랫폼 전략 수립을 위한 쿠버네티스 실전 활용서 - p103
          ```
* 파드는 생성될 때마다 새로운 내부 IP를 할당 받는다는데?
    * ```
      쿠버네티스에 배포된 오브젝트들은 IP가 변경돼도 CoreDNS를 통해
      도메인 이름(라벨링)으로 통신하여 서로 연결할 수 있습니다.
      컨테이너 인프라 환경 구축을 위한 쿠버네티스/도커 - p480
      ```
    * ![7](/assets/images/kubernetes-qna/7.png)
      파드를 삭제했을 때 다시 생성된 파드의 IP가 바뀐 것을 확인할 수 있다. (`172.16.132.1` -> `172.16.132.2`)

* 왜 파드가 여러개 존재하는가?
    * 대규모 서비스는 사용량이 많아지는 만큼 부하를 분산시켜야 한다. (규모가 작으면 굳이 그럴 필요가 없다.)
    * 이는 쿠버네티스가 대규모 서비스에 적합함을 의미하기도 한다.
    * 대규모 서비스의 경우 서비스가 죽어서 잠깐이라도 서비스가 안된다면 이는 엄청난 손실이기 때문에 자동으로 재배포하는 과정이 중요하다.
    * 롤링 업데이트를 통해 다운타임이 없는 배포가 가능하며, 배포된 어플리케이션에 문제가 발생했을 때도 빠른 시간 안에 롤백이 가능하다. 
    * 롤백 시에도 롤링 업데이트와 동일한 과정으로 무중단 배포가 유지된다. (잠깐 멈추는 것 자체가 문제 - <a href="https://tv.kakao.com/channel/3693125/cliplink/423597081">가동률 99.999%를 유지하는 카카오페이</a>)
        * ```
          새벽에 업데이트를 진행하는 이유는 다운타임의 영향을 최소화하기 위해서 + 원인 모를 오류가 발생했을 때 다시 롤백하는 시간을 확보하기 위해서

          필자의 경험에 비추었을 때, 과거 모 대기업에서 애플리케이션의 업데이트 본을 배포하는 과정에서 오류가 발생하여 이전 애플리케이션의 백업본으로 원복을 시도하였지만
          백업본 자체에 문제가 있어 결국 필요한 소프트웨어를 새로 설치하고 애플리케이션 소스 코드를 다시 빌드하고 배포를 진행하는 바람에 이틀 정도 서비스 중단 사태가 발생한 사례가 있었다.
          특히 모바일과 디지털 혁명으로 인해 애플리케이션 배포의 빈도가 2~3년 전에 비해 3~4배 높아졌고 인터넷 서비스 기업의 경우 하루에도 수십~수백 건의 배포가 일어나는 상황에서 무중단 배포와 롤백을 위한 방안의 수립은 기업의 영속성과도 직결된다고 볼 수 있다.
          디지털 플랫폼 전략 수립을 위한 쿠버네티스 실전 활용서 - p99
          ```
        * ```
          IaaS 서비스들은 장애 시 자동으로 복구되며, 서비스 요청 증가 시 가상서버를 자동으로 수평 확장할 수 있다고 주장한다. 하지만 애플리케이션까지도 자동화된 장애 처리와 수평 확장을 해줄 수 있느냐이다.
          서버에 대한 확장은 가능하지만, 애플리케이션 장애에 대해서는 수작업으로 복구하거나 HA(High Availability) 솔루션을 통해서 자동화된 장애 처리를 별도로 수행해야 한다.
          디지털 플랫폼 전략 수립을 위한 쿠버네티스 실전 활용서 - p42

          과거부터 현재까지 구축해왔던 인프라 통합 관리 솔루션들은 이미 구성된 인프라에 대한 관리에 집중되어 있었고 구축과 제어는 대부분 전문인력에 의한 수작업이었다.
          성능에 대한 모니터링(APM)을 통해 문제점을 가시화 해주지만 WAS에 대한 구축과 문제해결에 관여하지 않고, 이 부분은 전문 미들웨어 엔지니어의 역량에 좌지우지되곤 한다.
          특히 오픈소스 생테계로 들어가면 WAS, DB 같은 시스템 소프트웨어의 구축, 운영, 문제해결의 품질은 인력의 능력에 따라 편차가 심한 관계로 고객은 늘 특급 엔지니어를 요구하였고, 공급사는 비용 문제로 인해 초, 중급 위주의 엔지니어를 중심으로 인력을 유지해야 했다.
          실제로 장애가 생겨 긴급히 문제를 해결해야 할 때 특급 엔지니어가 필요한데 당장 지원 가능한 인력은 초, 중급인 경우가 대부분이다. 이로 인해 문제해결이 지연되어 서비스가 장시간 중단된 사례가 허다하다. 
          디지털 플랫폼 전략 수립을 위한 쿠버네티스 실전 활용서 - p88
          ```
        * ```
          문제나 장애가 발생한 자원은 일반적으로 삭제(Termination)하고 신규로 생성하여 할당한다. 그러므로 신뢰성과 안정성을 높이기 위해 견고하게 설계하지 않으며, 이를 보완하기 위해 다수의 자원을 클러스터로 묶어 운영하며, 한 두개의 자원에 장애가 발생하더라도 중단 없는 서비스를 제공한다.

          간혹 클라우드는 인프라의 안정성, 신뢰성, 가용성이 떨어져 아주 중요한 업무나 서비스에 적용하면 안된다고 주장하는 사람들이 있다.
          틀린 말은 아니다. 클라우드는 그러한 나약함을 알기에 오히려 레거시보다 더 철저히 가용성을 높이는 여러 안전장치를 제공한다.
          오히려 영원히 가동될 것만 같은 탄탄한 레거시가 재해를 만나 복구불능에 빠져 더 큰 서비스 재앙을 불러일으키는 현상을 필자는 23년의 IT 경혐상 더 많이 접해왔다.
          디지털 플랫폼 전략 수립을 위한 쿠버네티스 실전 활용서 - p26
          ```
        * ```
          OS는 일반적으로 20GB 정도의 디스크 용량을 할당하며, 여기에 호스팅되는 애플리케이션의 사이즈는 기껏해야 평균 수백 MB 정도이다.
          이 정도의 애플리케이션의 기동을 위해 바닥에 20GB의 용량을 깔고 간다는 것이 얼마나 비효율적인지는 삼척동자도 알 수 있다.

          사이즈가 작다는 의미는 기동 속도가 매우 빠르다는 것이다. 시스템이 부팅될 때 가장 많은 시간이 소요되는 부분은 하드웨어 디바이스를 구동시킬 때이다.
          만약 비정상적으로 종료되어 재부팅될 경우 파일 시스템 체크가 실행되기라도 한다면 수십 분에서 수 시간이 걸릴 수도 있다.
          그에 반해 컨테이너는 이미 사전에 구동되고 있는 Host OS의 자원을 사용하기 때문에 단순히 컨테이너 내 애플리케이션의 실행만 필요하므로 VM 대비 상당히 빠른 속도로 부팅된다.
          디지털 플랫폼 전략 수립을 위한 쿠버네티스 실전 활용서 - p78
          ```
    * 스케줄러에 의해 선택된 파드에서 사용하는 컨테이너들은 물리적으로 다른 컨테이너가 맞다.
        * 그래서 최대한 동일한 환경의 컨테이너로 구성해야 한다.
        * 컨테이너로 공통된 부분을 잘 묶어서 만들어야 한다. (개발자의 몫)

* 노드포트 서비스를 사용하여 포트를 열었을 때 마스터 노드와 워커 노드 IP에서 접속할 수 있는 이유
    * ```
      노드포트 서비스를 설정하면 모든 워커 노드의 특정 포트를 열고 들어오는 모든 요청을 노드포트 서비스로 전달합니다.
      그리고 노드포트 서비스는 해당 업무를 처리할 수 있는 파드로 요청을 전달합니다.
      컨테이너 인프라 환경 구축을 위한 쿠버네티스/도커 - p147
      ```
    * 애초에 기능이 노드로 구분되는 것이 아니다. 
        ![0](/assets/images/kubernetes-qna/0.png)
        파드에 할당된 워커 노드를 보면 `w1-k8s`, `w2-k8s`, `w3-k8s` 등 효율적으로 배치되어 있다.
        하나의 디플로이먼트 컨트롤러에 의해 5개의 파드가 생성되었고, 이는 각각의 워커 노드에 적절히 배치되었다.
        로드밸런서도 설정한 IP에 접속하면 컨트롤러에 의해 적절한 파드로 요청이 전달된다.
    * 하나의 포트에 하나의 서비스가 연결되어 있는 구조이며, 여러 노드 중 하나의 IP와 특정 포트만 알면 접근할 수 있다.
        * 노드 IP와 unknown 포트를 노출해야 한다는 단점이 있다.
        * 또한 노드를 생성할 때마다 IP가 다르다는 특징도 있다.
        * 이를 해결하기 위해 로드밸런서를 사용한다. 
        * ![1](/assets/images/kubernetes-qna/1.png)
        * ![2](/assets/images/kubernetes-qna/2.png)
          이미 할당된 포트를 사용하면 오류가 발생한다. (kubectl 명령어로 삭제해야 함)

* 노드가 죽으면 해당 노드 안의 파드는 어떻게 되는가?
    * `w2-k8s` 종료 전 - `in-ip-pod` 5개, `np-pods` 9개 존재
        * ![3](/assets/images/kubernetes-qna/3.png)
    * `w2-k8s` 종료 후 - `in-ip-pod` 2개, `np-pods` 3개 Terminating 상태이며, `w1-k8s`, `w3-k8s` 노드에 새로운 파드 생성
        * ![4](/assets/images/kubernetes-qna/4.png)
    * `w2-k8s` 다시 시작
        * Terminating 상태였던 파드들의 READY 값이 0/1로 바뀌었다.
        * 노드에 접근하여 사용 중인 파드가 있는지 조회한 것으로 보인다.
    * `최종 결과` - `w2-k8s`에서 사용하는 파드는 없기 때문에 목록에서 사라짐
        * ![5](/assets/images/kubernetes-qna/5.png)
    * 현재 상태에서 `in-ip-pod`의 수를 5개에서 9개로 늘렸을 때 - 모두 `w2-k8s`에 배치된다.
        * ![6](/assets/images/kubernetes-qna/6.png)



### 국내 대기업의 현대화를 통한 생산성 혁신 사례

|As Is|To Be|
|-----|-----|
|비지니스 변화에 따른 잦은 애플리케이션 배포를 수작업으로 진행|대내외 모든 서비스를 컨테이너화하고 이에 대한 빌드/배포를 CI/CD pipeline을 통해 자동화함|
|컨테이너 관리를 수작업으로 진행|쿠버네티스 기반 PaaS를 통해 서비스 카탈로그, 배포 자동화, 장애 복구 자동화, 서비스 확장 자동화, 모니터링 환경 마련|
|대고객 서비스의 경우 갑작스러운 부하 발생으로 장애가 발생할 경우 수작업 대응|애플리케이션 성능 측정치 기반으로 POD를 자동 확장하여 과부하로 인한 장애에 대응|
|OS 패치나 업그레이드 시 애플리케이션 호환성 문제로 이행하기 어려움|컨테이너화를 통해 OS 종속성에서 벗어남으로써 애플리케이션 호환성과 무관하게 OS 패치와 업그레이드 진행|
|오픈소스 WAS를 운영함에 있어 지원과 기술에 대한 표준이 없으며, 엔지니어의 스킬 능력에 따라 품질이 좌우됨|잘 튜닝된 오픈소스 WAS를 컨테이너 이미지화하여 전문 엔지니어를 통한 수작업 설치가 아닌 원클릭 이미지 할당 체계로 전환|

디지털 플랫폼 전략 수립을 위한 쿠버네티스 실전 활용서 - p164

### 국내 중견기업의 ERP 시스템의 현대화 사례

|As Is|To Be|
|-----|-----|
|유닉스 시스템, 상용 WAS와 DBMS로 인한 고비용과 벤더 종속적 구조|표준 x86 시스템, 오픈소스 WAS, 개방형 컨테이너 플랫폼을 통한 벤더 종속성 탈피|
|모놀로식 구조에 많은 서비스로 인한 성능 저하와 서비스 업데이트의 어려움 존재|업무별 5개의 서비스로 분리, 신규 서비스는 별도 서비스로 분리하여 개발|
|애플리케이션의 수작업 배포|CI/CD pipeline을 통한 자동화된 배포|
|장애 시 수작업 복구|쿠버네티스를 통한 자동 복구|
|백업 인프라의 부실로 복구에 하루 ~ 1주일 이상 소요됨|실시간 데이터 복제 및 재해복구 자동화 구축으로 1시간 이내 장애 및 재해복구 가능|
|배차 현황의 실시간 파악 불가능|즉시 모니터링 가능|
|연말 결산 손익계산서 결과 산정 시간이 24시간 소요|1시간 이내로 단축|

디지털 플랫폼 전략 수립을 위한 쿠버네티스 실전 활용서 - p169

## 참고

* <a href="https://www.yes24.com/Product/Goods/92426926">핵심만 콕! 쿠버네티스</a>
* <a href="https://www.yes24.com/Product/Goods/102099414">컨테이너 인프라 환경 구축을 위한 쿠버네티스/도커</a>
* <a href="https://seongjin.me/kubernetes-core-concepts/">쿠버네티스와 컨테이너 오케스트레이션, 그리고 핵심 설계 사상</a>
* <a href="https://seongjin.me/kubernetes-pods/">파드(Pod)의 개념과 생명 주기, 그리고 상태 진단을 위한 프로브(Probe) 활용</a>
* <a href="https://seongjin.me/kubernetes-service-types/">쿠버네티스에서 반드시 알아야 할 서비스(Service) 유형</a>
* <a href="https://saramin.github.io/2022-05-17-kubernetes-autoscaling/">Kubernetes에서 HPA를 활용한 오토스케일링</a>
* <a href="https://youtu.be/V-Ib-DdconY">K8S HPA 강의 제대로 듣고 있었습니까? 정신 차리십시오</a>
* <a href="https://youtu.be/76e2KOcmNSY">Kubernetes에서 확장 가능한 운영 HPA - 김상혁</a>
* <a href="https://tech.kakao.com/2018/12/24/kubernetes-deploy/">kubernetes를 이용한 서비스 무중단 배포</a>
* <a href="https://youtu.be/hJO1nxsB5uY">온프레미스에서도 로드밸런서를?</a>
